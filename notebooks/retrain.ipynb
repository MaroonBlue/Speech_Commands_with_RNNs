{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloning repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "!rm -r ./Speech_Commands_with_RNNs/\n",
    "!git clone https://github.com/MaroonBlue/Speech_Commands_with_RNNs.git\n",
    "%cd Speech_Commands_with_RNNs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install -U -q tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download form URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/download_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/download_test_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./utils/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./saved_data/X_t.npy ../X_t.npy\n",
    "!cp ./saved_data/y_t.npy ../y_t.npy\n",
    "!cp ./saved_data/X_v.npy ../X_v.npy\n",
    "!cp ./saved_data/y_v.npy ../y_v.npy\n",
    "!cp ./saved_data/X_test.npy ../X_test.npy\n",
    "!cp ./saved_data/y_test.npy ../y_test.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../X_t.npy ./saved_data/X_t.npy\n",
    "!cp ../y_t.npy ./saved_data/y_t.npy\n",
    "!cp ../X_v.npy ./saved_data/X_v.npy\n",
    "!cp ../y_v.npy ./saved_data/y_v.npy\n",
    "!cp ../X_test.npy ./saved_data/X_test.npy\n",
    "!cp ../y_test.npy ./saved_data/y_test.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from numpy import load\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from utils.utils import set_seeds, make_configs, step_decay\n",
    "from models.test_model import get_test_model\n",
    "from models.CNN_LSTM import CNN_LSTM1\n",
    "from models.GRU import GRU1, GRU2, GRU3\n",
    "from models.LSTM import LSTM1, LSTM2, LSTM3\n",
    "from models.simpleRNN import simpleRNN1, simpleRNN2, simpleRNN3\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY = 'wo-team'\n",
    "PROJECT = 'dl-rnn-audio'\n",
    "GROUP = 'simple-lstm-gru'\n",
    "NAME = '_'\n",
    "SAVE_PATH = 'weights/'\n",
    "\n",
    "models = {\n",
    "    'GRU3': GRU3,\n",
    "}\n",
    "base_config = {\n",
    "    'dataloader': {\n",
    "        'sample_rate': 8000,\n",
    "        'unknown_silence_samples': 2000,\n",
    "        'seed': 0,\n",
    "        'batch_size': 128,\n",
    "        'convert_to_image': False,\n",
    "    },\n",
    "    'training': {\n",
    "        'n_epochs': 50,\n",
    "        'dropout': 0.3,\n",
    "    },\n",
    "    'compile':{\n",
    "        'loss': 'sparse_categorical_crossentropy',\n",
    "        'optimizer': 'adam',\n",
    "        'metrics': ['accuracy', 'sparse_categorical_accuracy']\n",
    "    },\n",
    "    'model': {\n",
    "        'architecture': 'GRU3',\n",
    "        'model_init': None,\n",
    "        'id': None,\n",
    "        'save_path': None,\n",
    "    },\n",
    "    'early_stopper':{\n",
    "        'monitor': 'val_sparse_categorical_accuracy',\n",
    "        'min_delta': 0.001,\n",
    "        'patience': 3,\n",
    "        'verbose': 1,\n",
    "        'start_from_epoch': 5,\n",
    "        'restore_best_weights': True,\n",
    "    },\n",
    "    'checkpointer':{\n",
    "        'monitor': 'val_sparse_categorical_accuracy',\n",
    "        \"verbose\": 1,\n",
    "        'save_best_only': True\n",
    "    },\n",
    "    'scheduler': LearningRateScheduler(step_decay),\n",
    "    'other':{\n",
    "            'num_classes':12,\n",
    "    }\n",
    "}\n",
    "\n",
    "combinations = {\n",
    "    'seeds': {\n",
    "        'dict_path': ['dataloader', 'seed'],\n",
    "        'values': [0]\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "configs = make_configs(base_config, combinations)\n",
    "\n",
    "LOAD_PTH = \"./saved_data/\"\n",
    "X_t = load(LOAD_PTH + \"X_t.npy\")\n",
    "y_t = load(LOAD_PTH + \"y_t.npy\")\n",
    "X_v = load(LOAD_PTH + \"X_v.npy\")\n",
    "y_v = load(LOAD_PTH + \"y_v.npy\")\n",
    "y_t = np.argmax(y_t, axis=1).transpose()\n",
    "y_v = np.argmax(y_v, axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('0GRU3_seed0_dropout0,3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = base_config\n",
    "wandb.init(\n",
    "    project = PROJECT,\n",
    "    entity = ENTITY,\n",
    "    group = GROUP,\n",
    "    name = NAME,\n",
    "    config = config)\n",
    "\n",
    "input_shape = X_t.shape[1:]\n",
    "\n",
    "earlystopper = EarlyStopping(**config[\"early_stopper\"])\n",
    "checkpointer = ModelCheckpoint(NAME+'.h5', **config[\"checkpointer\"])\n",
    "lrate = config[\"scheduler\"]\n",
    "\n",
    "history = best_model.fit(\n",
    "            X_t,\n",
    "            y_t,\n",
    "            epochs=config['training']['n_epochs'],\n",
    "            validation_data=(X_v, y_v),\n",
    "            batch_size=config['dataloader']['batch_size'],\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                earlystopper, \n",
    "                checkpointer, \n",
    "                lrate,\n",
    "                WandbMetricsLogger(log_freq=5),\n",
    "                WandbModelCheckpoint(\"weights/wandb\")\n",
    "        ])\n",
    "save_path = os.path.join(SAVE_PATH, NAME)\n",
    "best_model.save(save_path)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
