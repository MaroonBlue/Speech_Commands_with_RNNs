{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Si2Uk1xlJmqZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaroonBlue/Speech_Commands_with_RNNs/blob/main/notebooks/main_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment setup"
      ],
      "metadata": {
        "id": "Si2Uk1xlJmqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning repository"
      ],
      "metadata": {
        "id": "U3yOj5hKKM2r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaE53h2rG-9Y",
        "outputId": "1a59a18e-e905-4e5f-ebe3-00955226c3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "rm: cannot remove './Speech_Commands_with_RNNs/': No such file or directory\n",
            "Cloning into 'Speech_Commands_with_RNNs'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 293 (delta 44), reused 58 (delta 29), pack-reused 213\u001b[K\n",
            "Receiving objects: 100% (293/293), 1.39 MiB | 9.15 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "/content/Speech_Commands_with_RNNs\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!rm -r ./Speech_Commands_with_RNNs/\n",
        "!git clone https://github.com/MaroonBlue/Speech_Commands_with_RNNs.git\n",
        "%cd Speech_Commands_with_RNNs/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "SC7iDRhkKQ0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install -U -q tensorflow tensorflow_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5dENBAmHRNl",
        "outputId": "53572e0b-ddb4-4991-cef7-64ee5f8b90ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
            "Collecting array-record\n",
            "  Downloading array_record-0.2.0-py39-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (5.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (1.15.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.0.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (8.1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.1.8)\n",
            "Collecting docker-pycreds\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting entrypoint2\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 18)) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 19)) (23.3.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 20)) (0.4.0)\n",
            "Collecting gitdb\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 23)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 24)) (1.0.0)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 25)) (0.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.59.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (1.53.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 28)) (3.8.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 29)) (3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 30)) (6.4.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 31)) (5.12.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 32)) (0.4.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 33)) (1.2.0)\n",
            "Collecting kapre\n",
            "  Downloading kapre-0.3.7.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (2.12.0)\n",
            "Requirement already satisfied: lazy_loader in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 36)) (0.2)\n",
            "Requirement already satisfied: libclang in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 37)) (16.0.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 38)) (0.10.0.post2)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 39)) (0.39.1)\n",
            "Requirement already satisfied: Markdown in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 40)) (3.4.3)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (2.1.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 42)) (0.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 43)) (1.0.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 44)) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 45)) (1.22.4)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 46)) (3.2.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 47)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 48)) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 49)) (1.5.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pooch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 52)) (1.6.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 53)) (2.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 54)) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 55)) (5.9.5)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 56)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 57)) (0.2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 58)) (2.21)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 59)) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 60)) (2022.7.1)\n",
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 62)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 63)) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 64)) (1.3.1)\n",
            "Requirement already satisfied: rsa in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 65)) (4.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 66)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 67)) (1.10.1)\n",
            "Collecting sentry-sdk\n",
            "  Downloading sentry_sdk-1.20.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 70)) (1.16.0)\n",
            "Collecting smmap\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 72)) (0.12.1)\n",
            "Requirement already satisfied: soxr in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 73)) (0.3.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 74)) (2.2.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 75)) (3.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 76)) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 77)) (4.65.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 78)) (4.5.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 79)) (2023.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 80)) (1.26.15)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 82)) (2.2.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 83)) (1.14.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 84)) (3.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse->-r requirements.txt (line 4)) (0.40.0)\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from kapre->-r requirements.txt (line 34)) (2.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->-r requirements.txt (line 44)) (67.7.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0.0->kapre->-r requirements.txt (line 34)) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0.0->kapre->-r requirements.txt (line 34)) (0.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0.0->kapre->-r requirements.txt (line 34)) (2.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->kapre->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0.0->kapre->-r requirements.txt (line 34)) (1.8.1)\n",
            "Building wheels for collected packages: kapre, pathtools\n",
            "  Building wheel for kapre (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kapre: filename=kapre-0.3.7-py3-none-any.whl size=29623 sha256=c890ea73d47c8eafde308926faa6b4979580a1bfb783a17320137da38e1f727b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/04/6b/a7c14b363e7942dad0706127cbf5b5817e51010175fda9026a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=637b1cd9beb77a1e1bc968b96e341e2f47f7d8683ff3fa7cbbdb173d7e441f3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built kapre pathtools\n",
            "Installing collected packages: patool, pathtools, entrypoint2, EasyProcess, smmap, setproctitle, sentry-sdk, pyunpack, einops, docker-pycreds, colorama, gitdb, GitPython, array-record, wandb, kapre\n",
            "Successfully installed EasyProcess-1.1 GitPython-3.1.31 array-record-0.2.0 colorama-0.4.6 docker-pycreds-0.4.0 einops-0.6.1 entrypoint2-1.1 gitdb-4.0.10 kapre-0.3.7 pathtools-0.1.2 patool-1.12 pyunpack-0.3 sentry-sdk-1.20.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading dataset"
      ],
      "metadata": {
        "id": "1wkIdcudKXIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download form URL"
      ],
      "metadata": {
        "id": "-YZwwC0Bdv_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python utils/download_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rew8dJE4HwHs",
        "outputId": "52b67d21-9ad9-452b-c9b6-8bf96b95a0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-24 18:16:19.973780: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-24 18:16:21.428617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data from https://storage.googleapis.com/kagglesdsdata/competitions/7634/46676/train.7z?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1682509177&Signature=jTadfpVkkZ2N5%2F8ExD7l5lB3sMxRPoteX6WbArpcnr%2BLyqb%2BW9ls4TvgszlpwgKS3KFVe3SuO6EC7jv5W%2FTPB935Vj6FRVZbg97NJlJwEusK2eggn%2FdVZNYEwEVO%2BcfoSZB4HQ3wGuo3oHO5OVVpWSCwgdxOZ%2B8fDjHf9r0oUUvc3EoF4B4pyw7b9jCpjxUG4UoKFNOoWH1ckXwilqK9lMS5paJYfF1Wja0HL2tcRPiHW2m9ooGrzGEL5pYdMYjucuohLTnt%2BJ5qV71CETkbamDsQsZ4GSqlUsK4yeGu1iY2CsJ8AswA%2FL8Zi2qHyi480%2BBzJn1XQJNslKeSA1MDmQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.7z\n",
            "1121103842/1121103842 [==============================] - 24s 0us/step\n",
            "Moved 6798 files to the validation directory\n",
            "Moved 6835 files to the test directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate and save training and validation data"
      ],
      "metadata": {
        "id": "MQH9lVpL4uUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./utils/dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WpOD62u4w_8",
        "outputId": "e6687985-3cdf-4ee2-af1b-442b7c9f9467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-24 18:19:06.305697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-24 18:19:08.494141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training dataset: 100% 22536/22536 [06:35<00:00, 56.99it/s]\n",
            "Validation dataset: 100% 6798/6798 [01:36<00:00, 70.46it/s]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy .npy files to drive"
      ],
      "metadata": {
        "id": "eSh7yQLu5Cxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!cp -R saved_data ../drive/MyDrive/project_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk23eYax5Gwz",
        "outputId": "0cc6b8fc-72de-4893-d664-169dad6a401c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy from drive"
      ],
      "metadata": {
        "id": "aBzzrerY5ffd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/project_data')\n",
        "!cp -R ../content/drive/project_data saved_data"
      ],
      "metadata": {
        "id": "SrhvSdU95hMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0f53c1a7-ca6c-4cf4-cd08-6b3458edbeff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aa0a49a9b693>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/project_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp -R ../content/drive/project_data saved_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy from local"
      ],
      "metadata": {
        "id": "RIIqyrd5Y5iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R data ../data"
      ],
      "metadata": {
        "id": "DCMQ5JhhY7fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R ../data data"
      ],
      "metadata": {
        "id": "jmo99bwjBPDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./saved_data/X_t.npy ../X_t.npy\n",
        "!cp ./saved_data/y_t.npy ../y_t.npy\n",
        "!cp ./saved_data/X_v.npy ../X_v.npy\n",
        "!cp ./saved_data/y_v.npy ../y_v.npy"
      ],
      "metadata": {
        "id": "XMD7PnuBlI5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ../X_t.npy ./saved_data/X_t.npy\n",
        "!cp ../y_t.npy ./saved_data/y_t.npy\n",
        "!cp ../X_v.npy ./saved_data/X_v.npy\n",
        "!cp ../y_v.npy ./saved_data/y_v.npy"
      ],
      "metadata": {
        "id": "ZoRf8SnBmdSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "hqJHBPmzOLRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and imports"
      ],
      "metadata": {
        "id": "FbUY1QNAOOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Speech_Commands_with_RNNs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-qe8XvoBte",
        "outputId": "f41d7175-47ef-4b7d-dfce-4638077ab065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Speech_Commands_with_RNNs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from numpy import load\n",
        "\n",
        "sys.path.append(\"./\")\n",
        "from utils.utils import set_seeds, make_configs, step_decay\n",
        "from models.test_model import get_test_model\n",
        "from models.CNN_LSTM import CNN_LSTM1\n",
        "from models.GRU import GRU1, GRU2, GRU3\n",
        "from models.LSTM import LSTM1, LSTM2, LSTM3\n",
        "from models.simpleRNN import simpleRNN1, simpleRNN2, simpleRNN3\n",
        "\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)"
      ],
      "metadata": {
        "id": "t7bALYwDOI_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs and data"
      ],
      "metadata": {
        "id": "s2DSa_UlOTYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENTITY = 'wo-team'\n",
        "PROJECT = 'dl-rnn-audio'\n",
        "GROUP = 'simple-lstm-gru'\n",
        "NAME = '_'\n",
        "SAVE_PATH = 'weights/'\n",
        "\n",
        "models = {\n",
        "    'CNN_LSTM': CNN_LSTM1,\n",
        "}\n",
        "\n",
        "base_config = {\n",
        "    'dataloader': {\n",
        "        'sample_rate': 8000,\n",
        "        'unknown_silence_samples': 2000,\n",
        "        'seed': 0,\n",
        "        'batch_size': 128,\n",
        "        'convert_to_image': False,\n",
        "    },\n",
        "    'training': {\n",
        "        'n_epochs': 50,\n",
        "        'dropout': 0.3,\n",
        "    },\n",
        "    'compile':{\n",
        "        'loss': 'sparse_categorical_crossentropy',\n",
        "        'optimizer': 'adam',\n",
        "        'metrics': ['accuracy', 'sparse_categorical_accuracy']\n",
        "    },\n",
        "    'model': {\n",
        "        'architecture': 'CNN_LSTM',\n",
        "        'model_init': None,\n",
        "        'id': None,\n",
        "        'save_path': None,\n",
        "    },\n",
        "    'early_stopper':{\n",
        "        'monitor': 'val_sparse_categorical_accuracy',\n",
        "        'min_delta': 0.001,\n",
        "        'patience': 4,\n",
        "        'verbose': 1,\n",
        "        'start_from_epoch': 10,\n",
        "        'restore_best_weights': True,\n",
        "    },\n",
        "    'checkpointer':{\n",
        "        'monitor': 'val_sparse_categorical_accuracy',\n",
        "        \"verbose\": 1,\n",
        "        'save_best_only': True\n",
        "    },\n",
        "    'scheduler': LearningRateScheduler(step_decay),\n",
        "    'other':{\n",
        "            'num_classes':12,\n",
        "    }\n",
        "}\n",
        "\n",
        "combinations = {\n",
        "    'seeds': {\n",
        "        'dict_path': ['dataloader', 'seed'],\n",
        "        'values': [0, 1, 2]\n",
        "    },\n",
        "    'dropout': {\n",
        "        'dict_path': ['training', 'dropout'],\n",
        "        'values': [0.3, 0.5]\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "configs = make_configs(base_config, combinations)\n",
        "\n",
        "LOAD_PTH = \"./saved_data/\"\n",
        "X_t = load(LOAD_PTH + \"X_t.npy\")\n",
        "y_t = load(LOAD_PTH + \"y_t.npy\")\n",
        "X_v = load(LOAD_PTH + \"X_v.npy\")\n",
        "y_v = load(LOAD_PTH + \"y_v.npy\")\n",
        "y_t = np.argmax(y_t, axis=1).transpose()\n",
        "y_v = np.argmax(y_v, axis=1).transpose()"
      ],
      "metadata": {
        "id": "rIlwhg_8vTpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "AeiVR0QXORC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_config = int(input(\"Provide ID of first config: \"))\n",
        "\n",
        "for i, config in enumerate(configs):\n",
        "    i = i + 54\n",
        "    if i < start_config:\n",
        "        continue\n",
        "\n",
        "    set_seeds(config['dataloader']['seed'])\n",
        "    config['model']['id'] = i\n",
        "    NAME = str(config['model']['id']) + config['model']['architecture'] + \"_seed\" + str(config['dataloader']['seed']) +\"_dropout\"+str(config['training']['dropout']).replace(\".\", \",\")\n",
        "    config['model']['model_init'] = models[config['model']['architecture']]\n",
        "\n",
        "    wandb.init(\n",
        "        project = PROJECT,\n",
        "        entity = ENTITY,\n",
        "        group = GROUP,\n",
        "        name = NAME,\n",
        "        config = config)\n",
        "    \n",
        "    l = len(configs)\n",
        "    print(f\"---------------\\nConfig {i+1}/{l}\\n---------------\\n\\n\")\n",
        "    print('Running config:', config, \"\\n\")\n",
        "\n",
        "    input_shape = X_t.shape[1:]\n",
        "\n",
        "    model = config['model']['model_init'](input_shape=input_shape, output_nodes=12, dropout=config['training']['dropout'])\n",
        "\n",
        "    model.compile(**config[\"compile\"])\n",
        "    earlystopper = EarlyStopping(**config[\"early_stopper\"])\n",
        "    checkpointer = ModelCheckpoint(NAME+'.h5', **config[\"checkpointer\"])\n",
        "    lrate = config[\"scheduler\"]\n",
        "\n",
        "    history = model.fit(\n",
        "                X_t,\n",
        "                y_t,\n",
        "                epochs=config['training']['n_epochs'],\n",
        "                validation_data=(X_v, y_v),\n",
        "                batch_size=config['dataloader']['batch_size'],\n",
        "                shuffle=True,\n",
        "                callbacks=[\n",
        "                    earlystopper, \n",
        "                    checkpointer, \n",
        "                    lrate,\n",
        "                    WandbMetricsLogger(log_freq=5),\n",
        "                    WandbModelCheckpoint(\"weights/wandb\")\n",
        "                ])\n",
        "    save_path = os.path.join(SAVE_PATH, NAME)\n",
        "    model.save(save_path)\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "oNkpnv67TVgX",
        "outputId": "53723e29-611a-4a2f-d84b-9f1fb835d203",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmartyna-majchrzak19\u001b[0m (\u001b[33mwo-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/Speech_Commands_with_RNNs/wandb/run-20230424_202418-xokdrqex</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/wo-team/dl-rnn-audio/runs/xokdrqex' target=\"_blank\">54CNN_LSTM_seed0_dropout0,3</a></strong> to <a href='https://wandb.ai/wo-team/dl-rnn-audio' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/wo-team/dl-rnn-audio' target=\"_blank\">https://wandb.ai/wo-team/dl-rnn-audio</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/wo-team/dl-rnn-audio/runs/xokdrqex' target=\"_blank\">https://wandb.ai/wo-team/dl-rnn-audio/runs/xokdrqex</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "Config 55/6\n",
            "---------------\n",
            "\n",
            "\n",
            "Running config: {'dataloader': {'sample_rate': 8000, 'unknown_silence_samples': 2000, 'seed': 0, 'batch_size': 128, 'convert_to_image': False}, 'training': {'n_epochs': 50, 'dropout': 0.3}, 'compile': {'loss': 'sparse_categorical_crossentropy', 'optimizer': 'adam', 'metrics': ['accuracy', 'sparse_categorical_accuracy']}, 'model': {'architecture': 'CNN_LSTM', 'model_init': <function CNN_LSTM1 at 0x7fe9110074c0>, 'id': 54, 'save_path': None}, 'early_stopper': {'monitor': 'val_sparse_categorical_accuracy', 'min_delta': 0.001, 'patience': 4, 'verbose': 1, 'start_from_epoch': 10, 'restore_best_weights': True}, 'checkpointer': {'monitor': 'val_sparse_categorical_accuracy', 'verbose': 1, 'save_best_only': True}, 'scheduler': <keras.callbacks.LearningRateScheduler object at 0x7fe9940cfd00>, 'other': {'num_classes': 12}} \n",
            "\n",
            "Changing learning rate to 0.001\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - ETA: 0s - loss: 1.3057 - accuracy: 0.5559 - sparse_categorical_accuracy: 0.5559\n",
            "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.50481, saving model to 54CNN_LSTM_seed0_dropout0,3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./weights/wandb)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 804s 5s/step - loss: 1.3057 - accuracy: 0.5559 - sparse_categorical_accuracy: 0.5559 - val_loss: 1.3875 - val_accuracy: 0.5048 - val_sparse_categorical_accuracy: 0.5048 - lr: 0.0010\n",
            "Changing learning rate to 0.001\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.8469 - sparse_categorical_accuracy: 0.8469\n",
            "Epoch 2: val_sparse_categorical_accuracy improved from 0.50481 to 0.70197, saving model to 54CNN_LSTM_seed0_dropout0,3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./weights/wandb)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/160 [==============================] - 746s 5s/step - loss: 0.4823 - accuracy: 0.8469 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.8564 - val_accuracy: 0.7020 - val_sparse_categorical_accuracy: 0.7020 - lr: 0.0010\n",
            "Changing learning rate to 0.001\n",
            "Epoch 3/50\n",
            " 80/160 [==============>...............] - ETA: 5:24 - loss: 0.3686 - accuracy: 0.8824 - sparse_categorical_accuracy: 0.8824"
          ]
        }
      ]
    }
  ]
}